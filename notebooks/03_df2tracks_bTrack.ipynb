{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49352f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "import btrack\n",
    "from btrack.constants import BayesianUpdates\n",
    "\n",
    "sys.path.append('../libraries')\n",
    "import input_functions as inp_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ace00128",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_file_path = r'Z:\\Garrett\\Livecell\\022725_Paracrine_Senescence_48hr\\slices\\B03_single_channel_movie\\downscaled\\DIC_movie\\data\\info_B03.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ade417d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "info_file = open(info_file_path, 'r')\n",
    "info_lines = info_file.readlines()\n",
    "info_file.close()\n",
    "\n",
    "# read info about the data frame\n",
    "exp_dir,df_name = inp_f.read_df_info(info_lines)\n",
    "\n",
    "df_dir = os.path.join(exp_dir,'df')\n",
    "save_dir = df_dir\n",
    "\n",
    "frames_to_exclude = inp_f.read_frames_2_exclude(info_lines)\n",
    "#frames_to_exclude = eval(frames_to_exclude)\n",
    "\n",
    "modelPath = os.path.join(exp_dir,'code','libraries','cell_config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12d00b",
   "metadata": {},
   "source": [
    "## Read in the data frame objects data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1afb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle(os.path.join(df_dir,df_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56aae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bfacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70555df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a structure suitable for tracking\n",
    "\n",
    "# choose objects \n",
    "sel_vector = [not(x in frames_to_exclude) for x in data_df.t]\n",
    "\n",
    "objects_gen = data_df.loc[sel_vector,['label','area','centroid-1','centroid-0','major_axis_length','minor_axis_length','t']]\n",
    "\n",
    "objects_gen.columns=['ID', 'area', 'x', 'y', 'major_axis_length','minor_axis_length','t']\n",
    "objects_gen['z']=0\n",
    "objects_gen['label']=5\n",
    "objects_gen['prob']=0\n",
    "objects_gen['dummy']=False\n",
    "objects_gen['states']=0\n",
    "\n",
    "#objects_gen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b974e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(objects_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gen.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b43d6",
   "metadata": {},
   "source": [
    "## Tracking proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file(modelPath)\n",
    "    \n",
    "    # approximate\n",
    "    tracker.update_method = BayesianUpdates.EXACT\n",
    "    tracker.max_search_radius = 100\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(objects_gen)\n",
    "\n",
    "    # set the volume (Z axis volume is set very large for 2D data)\n",
    "    #tracker.volume=((0, data_df.size_x[0]), (0, data_df.size_y[0]), (-1e5, 1e5))\n",
    "    tracker.volume = (\n",
    "        (0, data_df[\"size_x\"].iloc[0]),\n",
    "        (0, data_df[\"size_y\"].iloc[0]),\n",
    "        (-1e5, 1e5)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    #tracker.track_interactive(step_size=100)\n",
    "    tracker.track()\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    # optional: get the data in a format for napari\n",
    "    data, properties, graph = tracker.to_napari(ndim=2)\n",
    "    # pickle Napari data\n",
    "    with open(os.path.join(df_dir,'track.pkl'),'wb') as f:\n",
    "        pickle.dump([data,properties,graph],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed80fdcf",
   "metadata": {},
   "source": [
    "## Merging objects and tracking information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0841c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trackDataAll = pd.DataFrame(data,columns=['track_id','t','x','y'])\n",
    "trackDataAll['parent'] = properties['parent']\n",
    "trackDataAll['generation'] = properties['generation']\n",
    "trackDataAll['root'] = properties['root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a321d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trackDataAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1183fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trackDataAll.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851c7dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allData = pd.merge(left=data_df,right=trackDataAll,left_on=['centroid-0','centroid-1','t'],right_on=['x','y','t'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4ff1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Number of all objects: {len(allData)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many objects doesn't have a track_id\n",
    "test = np.sum(allData.track_id!=allData.track_id)\n",
    "print(f'Number of objects without track_id: {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187e177",
   "metadata": {},
   "source": [
    "## Be careful!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1335a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider removing\n",
    "#allData = allData.loc[allData.track_id==allData.track_id,:]\n",
    "#print(f'Number of all objects: {len(allData)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b83438",
   "metadata": {},
   "source": [
    "## Define promising tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7b8cb",
   "metadata": {},
   "source": [
    "This part is manual at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tracks = set(allData.track_id)\n",
    "print(len(my_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData['accepted'] = False\n",
    "allData['rejected'] = False\n",
    "allData['promise'] = False\n",
    "\n",
    "# Assuming track_lengths_to_test is a list of track lengths you want to test\n",
    "track_lengths_to_test = [0, 1, 5, 10, 15, 20, 30, 50, 60]  # Example thresholds\n",
    "\n",
    "# Initialize a dictionary to hold the count of tracks exceeding each length\n",
    "tracks_exceeding_length = {length: 0 for length in track_lengths_to_test}\n",
    "\n",
    "for track in set(allData.track_id):\n",
    "    # Prepare signals for this track\n",
    "    sel_signal = allData.loc[allData.track_id == track, ['t', 'mean_intensity-0_nuc', 'mean_intensity-0_ring']]\n",
    "    sel_signal.sort_values(by='t', inplace=True)\n",
    "    \n",
    "    track_len = len(sel_signal)\n",
    "    \n",
    "    # Update the count for each threshold exceeded\n",
    "    for length in track_lengths_to_test:\n",
    "        if track_len > length:\n",
    "            tracks_exceeding_length[length] += 1\n",
    "\n",
    "# Report on the number of tracks exceeding each length threshold\n",
    "for length, count in tracks_exceeding_length.items():\n",
    "    print(f\"Number of tracks longer than {length}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_length = 10  # Set based on results from previous block\n",
    "promise_list = []\n",
    "\n",
    "for track in set(allData.track_id):\n",
    "    # Prepare signals for this track\n",
    "    sel_signal = allData[allData.track_id == track]\n",
    "    sel_signal.sort_values(by='t', inplace=True)\n",
    "    \n",
    "    if len(sel_signal) > specific_length:\n",
    "        allData.loc[allData.track_id == track, 'promise'] = True\n",
    "        promise_list.append(track)\n",
    "\n",
    "print(f\"Number of promising tracks longer than {specific_length}: {len(promise_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaaf398",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(promise_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062a940",
   "metadata": {},
   "source": [
    "## Create columns for requested annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2034586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info about the tags (for annotating points on the tracks)\n",
    "flag_list = inp_f.read_flags(info_lines,df=allData)\n",
    "\n",
    "for flag in flag_list:\n",
    "    \n",
    "    allData[flag['flag_column']]=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df\n",
    "allData.to_pickle(os.path.join(df_dir,df_name))\n",
    "allData.to_csv(os.path.join(df_dir,df_name.replace('pkl','csv')),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell_tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
