{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49352f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "import btrack\n",
    "from btrack.constants import BayesianUpdates\n",
    "\n",
    "sys.path.append('../libraries')\n",
    "import input_functions as inp_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace00128",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_file_path = r'Z:\\Garrett\\Livecell\\030124_Lorenzo_livecell_TBHP_Dose_Curve\\Well_B03\\down\\data\\info_B03.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade417d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "info_file = open(info_file_path, 'r')\n",
    "info_lines = info_file.readlines()\n",
    "info_file.close()\n",
    "\n",
    "# read info about the data frame\n",
    "exp_dir,df_name = inp_f.read_df_info(info_lines)\n",
    "\n",
    "df_dir = os.path.join(exp_dir,'df')\n",
    "save_dir = df_dir\n",
    "\n",
    "frames_to_exclude = inp_f.read_frames_2_exclude(info_lines)\n",
    "#frames_to_exclude = eval(frames_to_exclude)\n",
    "\n",
    "modelPath = os.path.join(exp_dir,'code','libraries','cell_config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12d00b",
   "metadata": {},
   "source": [
    "## Read in the data frame objects data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1afb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle(os.path.join(df_dir,df_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e56aae03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75384"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70555df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a structure suitable for tracking\n",
    "\n",
    "# choose objects \n",
    "sel_vector = [not(x in frames_to_exclude) for x in data_df.t]\n",
    "\n",
    "objects_gen = data_df.loc[sel_vector,['label','area','centroid-1','centroid-0','major_axis_length','minor_axis_length','t']]\n",
    "\n",
    "objects_gen.columns=['ID', 'area', 'x', 'y', 'major_axis_length','minor_axis_length','t']\n",
    "objects_gen['z']=0\n",
    "objects_gen['label']=5\n",
    "objects_gen['prob']=0\n",
    "objects_gen['dummy']=False\n",
    "objects_gen['states']=0\n",
    "\n",
    "#objects_gen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b974e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(objects_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b43d6",
   "metadata": {},
   "source": [
    "## Tracking proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52a3c0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024/04/17 12:23:37 PM] Loaded btrack: C:\\Users\\gases\\.conda\\envs\\livecell_tracking\\Lib\\site-packages\\btrack\\libs\\libtracker.DLL\n",
      "[INFO][2024/04/17 12:23:37 PM] Starting BayesianTracker session\n",
      "[INFO][2024/04/17 12:23:37 PM] Loading configuration file: Z:\\Garrett\\Livecell\\030124_Lorenzo_livecell_TBHP_Dose_Curve\\Well_B03\\down\\code\\libraries\\cell_config.json\n",
      "[INFO][2024/04/17 12:23:37 PM] Objects are of type: <class 'pandas.core.frame.DataFrame'>\n",
      "[WARNING][2024/04/17 12:23:38 PM] `track_interactive` will be deprecated. Use `track` instead.\n",
      "[INFO][2024/04/17 12:23:38 PM] Starting tracking... \n",
      "[INFO][2024/04/17 12:23:38 PM] Update using: ['MOTION']\n",
      "[INFO][2024/04/17 12:23:38 PM] Tracking objects in frames 0 to 99 (of 240)...\n",
      "[INFO][2024/04/17 12:23:39 PM]  - Timing (Bayesian updates: 11.00ms, Linking: 0.00ms)\n",
      "[INFO][2024/04/17 12:23:39 PM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2024/04/17 12:23:39 PM]  - Stats (Active: 495, Lost: 13440, Conflicts resolved: 1978)\n",
      "[INFO][2024/04/17 12:23:39 PM] Tracking objects in frames 100 to 199 (of 240)...\n",
      "[INFO][2024/04/17 12:23:40 PM]  - Timing (Bayesian updates: 5.00ms, Linking: 3.00ms)\n",
      "[INFO][2024/04/17 12:23:40 PM]  - Probabilities (Link: 0.99976, Lost: 1.00000)\n",
      "[INFO][2024/04/17 12:23:40 PM]  - Stats (Active: 423, Lost: 29776, Conflicts resolved: 4155)\n",
      "[INFO][2024/04/17 12:23:40 PM] Tracking objects in frames 200 to 240 (of 240)...\n",
      "[INFO][2024/04/17 12:23:41 PM]  - Timing (Bayesian updates: 11.00ms, Linking: 1.00ms)\n",
      "[INFO][2024/04/17 12:23:41 PM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2024/04/17 12:23:41 PM] SUCCESS.\n",
      "[INFO][2024/04/17 12:23:41 PM]  - Found 6041 tracks in 240 frames (in 0.0s)\n",
      "[INFO][2024/04/17 12:23:41 PM]  - Inserted 4849 dummy objects to fill tracking gaps\n",
      "[INFO][2024/04/17 12:23:42 PM] Ending BayesianTracker session\n"
     ]
    }
   ],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file(modelPath)\n",
    "    \n",
    "    # approximate\n",
    "    tracker.update_method = BayesianUpdates.APPROXIMATE\n",
    "    tracker.max_search_radius = 500\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(objects_gen)\n",
    "\n",
    "    # set the volume (Z axis volume is set very large for 2D data)\n",
    "    tracker.volume=((0, data_df.size_x[0]), (0, data_df.size_y[0]), (-1e5, 1e5))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=100)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    #tracker.optimize()\n",
    "\n",
    "    # optional: get the data in a format for napari\n",
    "    data, properties, graph = tracker.to_napari(ndim=2)\n",
    "    # pickle Napari data\n",
    "    with open(os.path.join(df_dir,'track.pkl'),'wb') as f:\n",
    "        pickle.dump([data,properties,graph],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed80fdcf",
   "metadata": {},
   "source": [
    "## Merging objects and tracking information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0841c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trackDataAll = pd.DataFrame(data,columns=['track_id','t','x','y'])\n",
    "trackDataAll['parent'] = properties['parent']\n",
    "trackDataAll['generation'] = properties['generation']\n",
    "trackDataAll['root'] = properties['root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a321d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80233"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trackDataAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6851c7dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allData = pd.merge(left=data_df,right=trackDataAll,left_on=['centroid-0','centroid-1','t'],right_on=['x','y','t'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0f4ff1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all objects: 75384\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of all objects: {len(allData)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "124c8613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects without track_id: 0\n"
     ]
    }
   ],
   "source": [
    "# check how many objects doesn't have a track_id\n",
    "test = np.sum(allData.track_id!=allData.track_id)\n",
    "print(f'Number of objects without track_id: {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187e177",
   "metadata": {},
   "source": [
    "## Be careful!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1335a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider removing\n",
    "#allData = allData.loc[allData.track_id==allData.track_id,:]\n",
    "#print(f'Number of all objects: {len(allData)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b83438",
   "metadata": {},
   "source": [
    "## Define promising tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7b8cb",
   "metadata": {},
   "source": [
    "This part is manual at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e7d358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6041\n"
     ]
    }
   ],
   "source": [
    "my_tracks = set(allData.track_id)\n",
    "print(len(my_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c96b6c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks longer than 10: 1361\n",
      "Number of tracks longer than 20: 802\n",
      "Number of tracks longer than 30: 565\n",
      "Number of tracks longer than 40: 405\n",
      "Number of tracks longer than 50: 335\n",
      "Number of tracks longer than 70: 232\n",
      "Number of tracks longer than 90: 172\n",
      "Number of tracks longer than 100: 157\n",
      "Number of tracks longer than 110: 147\n",
      "Number of tracks longer than 120: 134\n"
     ]
    }
   ],
   "source": [
    "allData['accepted'] = False\n",
    "allData['rejected'] = False\n",
    "allData['promise'] = False\n",
    "\n",
    "# Assuming track_lengths_to_test is a list of track lengths you want to test\n",
    "track_lengths_to_test = [10, 20, 30, 40, 50, 70, 90, 100, 110, 120]  # Example thresholds\n",
    "\n",
    "# Initialize a dictionary to hold the count of tracks exceeding each length\n",
    "tracks_exceeding_length = {length: 0 for length in track_lengths_to_test}\n",
    "\n",
    "for track in set(allData.track_id):\n",
    "    # Prepare signals for this track\n",
    "    sel_signal = allData.loc[allData.track_id == track, ['t', 'mean_intensity-0_nuc', 'mean_intensity-0_ring']]\n",
    "    sel_signal.sort_values(by='t', inplace=True)\n",
    "    \n",
    "    track_len = len(sel_signal)\n",
    "    \n",
    "    # Update the count for each threshold exceeded\n",
    "    for length in track_lengths_to_test:\n",
    "        if track_len > length:\n",
    "            tracks_exceeding_length[length] += 1\n",
    "\n",
    "# Report on the number of tracks exceeding each length threshold\n",
    "for length, count in tracks_exceeding_length.items():\n",
    "    print(f\"Number of tracks longer than {length}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a7ad0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gases\\AppData\\Local\\Temp\\ipykernel_11896\\2312636104.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sel_signal.sort_values(by='t', inplace=True)  # Ensure chronological order\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of promising tracks longer than 50: 335\n"
     ]
    }
   ],
   "source": [
    "specific_length = 50  # Example specific length\n",
    "promise_list = []\n",
    "\n",
    "for track in set(allData.track_id):\n",
    "    # Prepare signals for this track\n",
    "    sel_signal = allData[allData.track_id == track]\n",
    "    sel_signal.sort_values(by='t', inplace=True)  # Ensure chronological order\n",
    "    \n",
    "    if len(sel_signal) > specific_length:\n",
    "        allData.loc[allData.track_id == track, 'promise'] = True\n",
    "        promise_list.append(track)\n",
    "\n",
    "print(f\"Number of promising tracks longer than {specific_length}: {len(promise_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9462e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old method of setting promising tracks\n",
    "'''\n",
    "allData['accepted'] = False\n",
    "allData['rejected'] = False\n",
    "allData['promise'] = False\n",
    "\n",
    "# mark tracks longer than 100 as promising\n",
    "tracks_set = set(allData.track_id)\n",
    "\n",
    "track_len=[]\n",
    "promise_list = []\n",
    "for track in tracks_set:\n",
    "    \n",
    "    # prepare signals for this track\n",
    "    sel_signal = allData.loc[allData.track_id == track,['t','mean_intensity-1_nuc','mean_intensity-1_ring']]\n",
    "    sel_signal.sort_values(by='t',inplace=True)\n",
    "    sel_mean = sel_signal.rolling(9,min_periods = 9,center=True).mean()\n",
    "    \n",
    "    # test - length\n",
    "    track_test = len(sel_signal)>50\n",
    "    \n",
    "    track_len.append(len(sel_signal))\n",
    "    \n",
    "    # test - DHB presence\n",
    "    dhb_test = np.sum(sel_mean['mean_intensity-1_nuc'] > (sel_mean['mean_intensity-1_ring']+100)) > 10\n",
    "    \n",
    "    if (track_test and dhb_test):\n",
    "        \n",
    "        promise_list.append(track)\n",
    "        \n",
    "        allData.loc[allData.track_id==track,'promise'] = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eaaf398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(promise_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062a940",
   "metadata": {},
   "source": [
    "## Create columns for requested annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2034586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info about the tags (for annotating points on the tracks)\n",
    "flag_list = inp_f.read_flags(info_lines,df=allData)\n",
    "\n",
    "for flag in flag_list:\n",
    "    \n",
    "    allData[flag['flag_column']]=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84b4e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df\n",
    "allData.to_pickle(os.path.join(df_dir,df_name))\n",
    "#allData.to_csv(os.path.join(df_dir,df_name.replace('pkl','csv')),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
